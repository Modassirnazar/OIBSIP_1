# -*- coding: utf-8 -*-
"""IRIS_Flower_CLassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OtrqQNMONPMn3yjegmitl-lE9d8vQM3T

# **IRIS FLOWER CLASSIFICATION**

**Importing Libraries**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import datasets
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

"""**Load the dataset**"""

# You can also directly load the dataset.
# iris = datasets.load_iris()
# X = iris.data
# y = iris.target

df = pd.read_csv("/content/IRIS.csv")
X = df[['sepal_length','sepal_width','petal_length','petal_width']]
y = df['species']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features by removing the mean and scaling to unit variance
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#--First five rows--
df.head()

df.describe()

"""**Checking for NULL values**"""

df.isnull().sum()

X_train.shape, X_test.shape

y.value_counts()

"""**All three categories are equally divided i.e. 50 each**"""

sns.countplot(x=df['species'],hue=df['species'])

# Visualize the whole dataset
sns.pairplot(df, hue='species')

"""**Training & Testing**
* Support Vector Machine (SVM)
* k-Nearest Neighbors (k-NN)
* Decision Tree
"""

# Support Vector Machine (SVM)
svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)
svm_classifier.fit(X_train, y_train)
y_pred_svm = svm_classifier.predict(X_test)
accuracy_svm = accuracy_score(y_test, y_pred_svm)

# k-Nearest Neighbors (k-NN)
knn_classifier = KNeighborsClassifier(n_neighbors=3)
knn_classifier.fit(X_train, y_train)
y_pred_knn = knn_classifier.predict(X_test)
accuracy_knn = accuracy_score(y_test, y_pred_knn)

# Decision Tree
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)
y_pred_dt = dt_classifier.predict(X_test)
accuracy_dt = accuracy_score(y_test, y_pred_dt)

# Print accuracies
print(f"SVM Accuracy: {accuracy_svm * 100:.2f}%")
print(f"k-NN Accuracy: {accuracy_knn * 100:.2f}%")
print(f"Decision Tree Accuracy: {accuracy_dt * 100:.2f}%")

"""*SVM Classification Report*"""

# A detailed classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_svm))

"""*KNN Classification Report*"""

print(classification_report(y_test, y_pred_knn))

"""*DT Classification Report*"""

print(classification_report(y_test, y_pred_dt))

# Calculate the correlation matrix
correlation_matrix = X.corr()

# Create a heatmap of the correlation matrix
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='cool', fmt=".2f", linewidths=0.5)
plt.title('Correlation Matrix Heatmap')
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

# Create a Random Forest classifier
rf_classifier = RandomForestClassifier(random_state=42)

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Perform grid search with cross-validation
grid_search = GridSearchCV(rf_classifier, param_grid, cv=5)
grid_search.fit(X_train, y_train)

# Get the best parameters from the grid search
best_params = grid_search.best_params_

# Train the model with the best parameters
best_rf_classifier = RandomForestClassifier(**best_params, random_state=42)
best_rf_classifier.fit(X_train, y_train)

# Make predictions on the testing data
y_pred_rf = best_rf_classifier.predict(X_test)

# Calculate the accuracy of the model
accuracy_rf = accuracy_score(y_test, y_pred_rf)

print(f"Best Parameters: {best_params}")
print(f"Accuracy: {accuracy_rf * 100:.2f}%")

"""**Accuracy of Different Models**"""

# Create a DataFrame with model names and accuracy values
results_df = pd.DataFrame({
    'Model': ['SVM', 'k-NN', 'Decision Tree', 'Random Forest'],
    'Accuracy': [accuracy_svm, accuracy_knn, accuracy_dt, accuracy_rf]
})

# Plot the bar graph
plt.figure(figsize=(8, 6))
sns.barplot(x='Model', y='Accuracy', data=results_df, palette='viridis')
plt.title('Accuracy of Different Models')
plt.ylim(0, 1)  # Set y-axis limit to the range of 0 to 1 (accuracy range)
plt.show()

